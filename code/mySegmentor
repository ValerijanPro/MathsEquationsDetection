'''

IMPORTANT:

Calling this file with this command on my PC:

& "C:/Program Files/Python38/python.exe" c:/Master/MLCV/mathRecognition/Master-MathProject-master/code/mySegmentor

Just make sure the datasets are in the correct folders!

'''



import numpy as np
from glob import glob
import xml.etree.ElementTree as ET
import time
import copy
import torch
import torchvision
import torchvision.transforms as transforms
from skimage.io import imread, imsave
import convertInkmlToImg
import segmenter
import segmentSelect
from skimage import img_as_ubyte
from PIL import Image
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt
namespace = "{http://www.w3.org/2003/InkML}"

def getTraceGroup(inkFilePath):
   temp = ET.parse(inkFilePath)
   root = temp.getroot()
   traceGroups = root.findall(namespace + 'traceGroup')[0].findall(namespace + 'traceGroup')
   return [[int(view.get('traceDataRef')) for view in group.findall(namespace + 'traceView')] for group in traceGroups]

inkFiles = glob('./Master-MathProject-master/data/TrainINKML/TrainINKML/**/*.inkml', recursive = True)

print(len(inkFiles))

def getData(inkFiles):
  for inkFile in inkFiles:
    #we get dictionary: {traceID : tuples of coordinates}
    traces = convertInkmlToImg.parse_inkml(inkFile);
    if(traces is None): 
        continue
    #get all hypothesis from the number of traces
    hypothesisList = segmenter.generateHypSeg(len(traces))
    #get all traceView elements inside traceGroup elements inside traceGroup elements
    trace_groups_truth = getTraceGroup(inkFile)
    for _, hyp in enumerate(hypothesisList):
      #if hypothesis is inside the traceGroup, then it is the correct hypothesis
      truth = float(1.0) if hyp in trace_groups_truth else float(0.0)
      hyp = [str(i) for i in hyp]
      #convert image to tensor
      img = convertInkmlToImg.convert_to_imgs(convertInkmlToImg.get_traces_data(traces, hyp), 32) / 255
      img = torch.tensor([img.tolist()])
      #we return IMAGES and 0/1 floats
      yield img, truth
  
a = list(getData(inkFiles))
print("Dataset length")
print(len(a))
datasetSize = len(a)

#define the training set size
trainSize = datasetSize // 2
remaining_size = datasetSize - trainSize

# Split the remaining part into validation and test sets
validationSize = remaining_size // 2
testSize = remaining_size - validationSize
#size of the mini batch
minibatchsize = 32

#split the full train part as train and validation:
trainset, validationset, testSet = torch.utils.data.random_split(a, [trainSize,validationSize,testSize])

trainloader = torch.utils.data.DataLoader(trainset, batch_size=minibatchsize,
                                          shuffle=True, num_workers=0)

validationloader = torch.utils.data.DataLoader(validationset, batch_size=minibatchsize,
                                          shuffle=False, num_workers=0)

testLoader = torch.utils.data.DataLoader(testSet, batch_size=minibatchsize,
                                          shuffle=False, num_workers=0)



nb_used_sample = 0
running_loss = 0.0
num_epochs = 5
print_every = 200

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")




# this class define the CNN architecture
# default architecture is close to LeNet5 one
class NetCNN(nn.Module):
    def __init__(self):
        super(NetCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 1)


    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        x = torch.sigmoid(x)
        return x.view(-1)
    

net = NetCNN()
net.to(device) # move it to GPU or CPU


criterion = nn.BCELoss()
optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)


val_err_array = np.array([])
train_err_array = np.array([])
nb_sample_array = np.array([])

# best system results
best_val_loss = 1000000
best_epoch = 0
best_model =  copy.deepcopy(net)

nb_used_sample = 0
running_loss = 0.0
num_epochs = 5
print_every = 200

for epoch in range(num_epochs):  # loop over the dataset multiple times
    start_time = time.time()
    for i, data in enumerate(trainloader, 0):
        # get the inputs
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device) # if possible, move them to GPU

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels.to(torch.float32))
        loss.backward()
        optimizer.step()
        # count how many samples have been used during the training
        nb_used_sample += minibatchsize
        # print/save statistics
        running_loss += loss.item()
        if nb_used_sample % (print_every * minibatchsize) == 0:    # print every ""print_every"" mini-batches
            train_err = (running_loss / (print_every * minibatchsize))
            print('Epoch %d batch %5d ' % (epoch + 1, i + 1))
            print('Train loss : %.3f' % train_err)
            running_loss = 0.0
            #evaluation on validation set
            totalValLoss = 0.0
            with torch.no_grad():
                for data in validationloader:
                    images, labels = data
                    images, labels = images.to(device), labels.to(device)
                    outputs = net(images)
                    loss = criterion(outputs, labels.to(torch.float32))
                    totalValLoss += loss.item()
            val_err = (totalValLoss / len(validationset))
            print('Validation loss mean : %.3f' % val_err)

            train_err_array = np.append(train_err_array, train_err)
            val_err_array = np.append(val_err_array, val_err)
            nb_sample_array = np.append(nb_sample_array, nb_used_sample)

            if val_err<best_val_loss:
                best_val_loss = val_err
                best_epoch = epoch + 1
                best_nb_sample = nb_used_sample

            # save the model only when loss is better
            best_model =  copy.deepcopy(net)
    print("Epoch {} of {} took {:.3f}s".format(epoch + 1, num_epochs, time.time() - start_time))

print('Finished Training')


plt.clf()
plt.xlabel('epoch')
plt.ylabel('val / train LOSS')
plt.title('Symbol classifier')
green_point_index = np.where(nb_sample_array == best_nb_sample)[0][0]
plt.plot(nb_sample_array.tolist(), val_err_array.tolist(), 'b', nb_sample_array.tolist(), train_err_array.tolist(), 'r', [nb_sample_array[green_point_index]], [val_err_array[green_point_index]], 'go', label=f'Min Validation Loss (Epoch {best_epoch})')

#save the LOSS in the resultMLP png file
plt.savefig('./Master-MathProject-master/code/segmentorLoss.png')


#save the model
torch.save(best_model, "./Master-MathProject-master/code/models/best_segmentor.nn")

#test the accuracy on the whole testDataset
correct = 0
total = 0
with torch.no_grad():
    for data in testLoader:
        images, labels = data
        images, labels = images.to(device), labels.to(device)
        outputs = best_model(images)
        predicted = (outputs > 0.5).float()
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the test images: %3.2f %%' % (
    100.0 * correct / total))

