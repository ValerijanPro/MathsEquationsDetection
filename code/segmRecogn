import numpy as np
from glob import glob
import xml.etree.ElementTree as ET
import time
import copy
import torch
import torchvision
import torchvision.transforms as transforms
from skimage.io import imread, imsave
import convertInkmlToImg
import segmenter
import segmentSelect
import torch.nn as nn
import torch.nn.functional as F
import os
from skimage import img_as_ubyte
import torch
from torch.autograd import Variable
from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout
from torch.optim import Adam, SGD
import torch.nn as nn
import torch.nn.functional as F
import selectBestSeg
import shutil


#define the class here also, so that it is properly loaded as a NetCNN variable
class NetCNN(nn.Module):
    def __init__(self):
        super(NetCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 1)


    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        x = torch.sigmoid(x)
        return x.view(-1)

net = torch.load("./Master-MathProject-master/code/models/best_segmentor.nn")
net.eval()

#inkFiles2 = glob('./Master-MathProject-master/data/formulaire001-equation001.inkml', recursive = True)
inkFiles = glob('./Master-MathProject-master/data/TestEM2014/TestEM2014/*.inkml', recursive = True)

output_dir = "./Master-MathProject-master/myLGfiles"
shutil.rmtree(output_dir, ignore_errors=True)
os.makedirs(output_dir, exist_ok=True)

for inkFile in inkFiles:
    #get file name
    file_name = os.path.basename(inkFile)
    #get the traces
    traces = convertInkmlToImg.parse_inkml(inkFile)
    if(traces is None):
        continue
    numberOfTraces = len(traces)

    #get the hypotheses from the number of traces (0, 1, 2, [0,1], [1,2])
    hypotheses = segmenter.generateHypSeg(numberOfTraces)

    #returns the STRING for each hypothesis. Example for [0, (0,1)] hypotheses it will return:

    LGfileOutputText = segmenter.toLG(hypotheses)

    #get the traces from the inkml file
    traces = convertInkmlToImg.parse_inkml(inkFile)
    # from the generated LG file text, get back the array of hypotheses in this format: 
    # [HypothesisName : arrayOfTraces]
    hypotheses = convertInkmlToImg.parseLG(LGfileOutputText.split("\n"))
    #dictionary : (hypName : probability)
    probabilitiesForEachHypothesis = {}

    def computeProbSeg(alltraces, hyp):
        im = convertInkmlToImg.convert_to_imgs(convertInkmlToImg.get_traces_data(alltraces, hyp[1]), 32)
        im = torch.tensor(im).to(torch.float32).unsqueeze(0)
        return net(im)
    #get the probabilities for each hypothesis being the correct one
    for hypothesis in hypotheses:
        # Compute the probability using the neural network
        prob = (computeProbSeg(traces, hypothesis)).float()
        # Store the probability as a Python float
        probabilitiesForEachHypothesis[hypothesis[0]] = prob.item()
    hypotheses = [h for h in hypotheses if probabilitiesForEachHypothesis[h[0]]]
    #helper function used to remove same subsets of the hypothesis array
    #not used in the final implementation, but useful generally
    def filterSubsetHypotheses(hypotheses):
        filtered_hypotheses = []
        for hypothesis in hypotheses:
        # Assume the hypothesis is not included in any other
            included_in_other = False
            
            # Check against each other hypothesis
            for other_hypothesis in hypotheses:
                if hypothesis != other_hypothesis:
                    # Check if the traces of hypothesis are a subset of other_hypothesis
                    if set(hypothesis[1]).issubset(set(other_hypothesis[1])):
                        included_in_other = True
                        break

            # If the hypothesis is not included in any other, add it to the filtered list
            if not included_in_other:
                filtered_hypotheses.append(hypothesis)
        return filtered_hypotheses

    #get the string that would be written in LG files
    def toLG(setHyp):
        output = ""
        for hyp in (setHyp):
            hyp_name = hyp[0]  # Get the hypothesis name
            trace_numbers = [int(trace) for trace in hyp[1]]  # Convert trace strings to integers
            output += f"O,{hyp_name},*,1.0,{','.join(map(str, trace_numbers))}\n"
        return output
    LGfileOutputText = toLG(hypotheses)

    #get the hypotheses from the LG file output text
    hypset = selectBestSeg.parseLGscore(LGfileOutputText)
    #take only the best and most consistent hypotheses
    bestLG = selectBestSeg.selectBestSeg(hypset)

    output = ""
    for symb in bestLG:
        output += "O," + symb['id'] + "," + symb['cl'] + "," + str(symb['sc']) + "," + ",".join([str(s) for s in symb['strk']]) + "\n"

    hypotheses = convertInkmlToImg.parseLG(output.split("\n"))

    #end of segmentation

    #classification task begin

    class NetCNN2(nn.Module):
        def __init__(self):
            super(NetCNN2, self).__init__()

            self.cnn_layers = Sequential(
                # Defining a 2D convolution layer
                Conv2d(1, 4, kernel_size=5, stride=1, padding=1),
                BatchNorm2d(4),
                ReLU(inplace=True),
                MaxPool2d(kernel_size=2, stride=2),
                # Defining another 2D convolution layer
                Conv2d(4, 4, kernel_size=5, stride=1, padding=1),
                BatchNorm2d(4),
                ReLU(inplace=True),
                MaxPool2d(kernel_size=2, stride=2),
            )

            self.linear_layers = Sequential(
                Linear(144, 101)
            )

        # Defining the forward pass
        def forward(self, x):
            x = self.cnn_layers(x)
            x = x.view(x.size(0), -1)
            x = self.linear_layers(x)
            return x

    recognizer = NetCNN2()
    recognizer = torch.load("./Master-MathProject-master/code/models/bestClassifier.nn",map_location=torch.device('cpu'))
    recognizer.eval()

    label_mapping = {label: idx for idx, label in enumerate(['!', '(', ')', '+', ',', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', 'a', 'alpha', 'A_', 'b', 'beta', 'B_', 'c', 'cos', 'C_', 'd', 'Delta', 'div', 'div_op', 'dot', 'e', 'exists', 'E_', 'f', 'forall', 'F_', 'g', 'gamma', 'geq', 'gt', 'G_', 'h', 'H_', 'i', 'in', 'infty', 'int', 'I_', 'j', 'k', 'l', 'lambda', 'ldots', 'leq', 'lim', 'log', 'lt', 'L_', 'm', 'mu', 'M_', 'n', 'neq', 'N_', 'o', 'p', 'phi', 'pi', 'pipe', 'pm', 'prime', 'P_', 'q', 'r', 'rightarrow', 'R_', 's', 'sigma', 'sin', 'sqrt', 'sum', 'S_', 't', 'tan', 'theta', 'times', 'T_', 'u', 'v', 'V_', 'w', 'x', 'X_', 'y', 'Y_', 'z', '[', ']', '{', '}'])}

    index_to_label = {idx: label.replace('\\', '') for idx, label in enumerate(['!', '(', ')', '+', ',', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', 'a', 'alpha', 'A_', 'b', 'beta', 'B_', 'c', 'cos', 'C_', 'd', 'Delta', 'div', 'div_op', 'dot', 'e', 'exists', 'E_', 'f', 'forall', 'F_', 'g', 'gamma', 'geq', 'gt', 'G_', 'h', 'H_', 'i', 'in', 'infty', 'int', 'I_', 'j', 'k', 'l', 'lambda', 'ldots', 'leq', 'lim', 'log', 'lt', 'L_', 'm', 'mu', 'M_', 'n', 'neq', 'N_', 'o', 'p', 'phi', 'pi', 'pipe', 'pm', 'prime', 'P_', 'q', 'r', 'rightarrow', 'R_', 's', 'sigma', 'sin', 'sqrt', 'sum', 'S_', 't', 'tan', 'theta', 'times', 'T_', 'u', 'v', 'V_', 'w', 'x', 'X_', 'y', 'Y_', 'z', '[', ']', '{', '}'])}


    def computeClProb(alltraces, hyp, min_threshol, saveIm = False):
        #get an image from the trace
        img = convertInkmlToImg.convert_to_imgs(convertInkmlToImg.get_traces_data(alltraces, hyp[1]), 32) / 255
        #convert to tensor
        img = torch.tensor([img.tolist()]).unsqueeze(0)
        img_np_uint8 = img_as_ubyte(img)
        #use the recognizer to get the output characters from the given image
        outputs = recognizer(img)
        #only take the maximum probable output characters
        numerical_output = torch.argmax(outputs, 0)
        # Convert numerical output back to string label
        predicted_label = index_to_label[numerical_output.item()]
        return predicted_label

    classes = [x[0].replace('C:/Master/MLCV/mathRecognition/Master-MathProject-master/data/trainingSymbolsGT_png/trainingSymbolsGT_png/','') for x in os.walk('C:/Master/MLCV/mathRecognition/Master-MathProject-master/data/trainingSymbolsGT_png/trainingSymbolsGT_png/')][1:] # all subdirectories, except itself

    
    output_lg_file_path = output_dir + "/"+file_name

    output = ""
    for h in hypotheses:
        character = computeClProb(traces, h, 0.05)
        output += "O," + h[0] + "," + character + "," + ",".join([str(s) for s in h[1]]) + "\n"



    # Write the output string to the LG file
    with open(output_lg_file_path, "w") as lg_file:
        lg_file.write(output)
    #print(output)

''' 
    ###!!!!!! IMPORTANT ###########
    the classifer's LG files and the ground-truth LG files are compared
    using the .evaluate script from LGEVAL library
    The output from the .evaluate script is in the "Results_myLGfiles" directory
'''